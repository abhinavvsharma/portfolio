import React, { useEffect, useRef } from 'react';
import { StaticImage } from 'gatsby-plugin-image';
import styled from 'styled-components';
import { srConfig } from '@config';
import sr from '@utils/sr';
import { usePrefersReducedMotion } from '@hooks';

const StyledAboutSection = styled.section`
  max-width: 900px;

  .inner {
    display: grid;
    grid-template-columns: 3fr 2fr;
    grid-gap: 50px;
    text-align: justify;

    @media (max-width: 768px) {
      display: block;
    }
  }
`;
const StyledText = styled.div`
  ul.skills-list {
    display: grid;
    grid-template-columns: repeat(2, minmax(140px, 200px));
    grid-gap: 0 10px;
    padding: 0;
    margin: 20px 0 0 0;
    overflow: hidden;
    list-style: none;

    li {
      position: relative;
      margin-bottom: 10px;
      padding-left: 20px;
      font-family: var(--font-mono);
      font-size: var(--fz-xs);

      &:before {
        content: '▹';
        position: absolute;
        left: 0;
        color: var(--green);
        font-size: var(--fz-sm);
        line-height: 12px;
      }
    }
  }
`;
const StyledPic = styled.div`
  position: relative;
  max-width: 300px;

  @media (max-width: 768px) {
    margin: 50px auto 0;
    width: 70%;
  }

  .wrapper {
    ${({ theme }) => theme.mixins.boxShadow};
    display: block;
    position: relative;
    width: 100%;
    border-radius: var(--border-radius);
    background-color: var(--white);

    &:hover,
    &:focus {
      outline: 0;

      &:after {
        top: 15px;
        left: 15px;
      }

      .img {
        filter: none;
        mix-blend-mode: normal;
      }
    }

    .img {
      position: relative;
      border-radius: var(--border-radius);
      mix-blend-mode: multiply;
      transition: var(--transition);
    }

    &:before,
    &:after {
      content: '';
      display: block;
      position: absolute;
      width: 100%;
      height: 100%;
      border-radius: var(--border-radius);
      transition: var(--transition);
    }

    &:before {
      top: 0;
      left: 0;
      background-color: var(--navy);
      mix-blend-mode: screen;
    }

    &:after {
      border: 2px solid var(--green);
      top: 20px;
      left: 20px;
      z-index: -1;
    }
  }
`;

const About = () => {
  const revealContainer = useRef(null);
  const prefersReducedMotion = usePrefersReducedMotion();

  useEffect(() => {
    if (prefersReducedMotion) {
      return;
    }

    sr.reveal(revealContainer.current, srConfig());
  }, []);

  const skills = ['PyTorch', 'TensorRT', 'Docker', 'Kubernetes', 'NVIDIA DeepStream', 'CUDA'];

  return (
    <StyledAboutSection id="about" ref={revealContainer}>
      <h2 className="numbered-heading">About Me</h2>

      <div className="inner">
        <StyledText>
          <div>

          <p>
          As an engineer and passionate Machine Learning and Computer Vision researcher, I am dedicated to create innnovative 
          and useful things by exploring the limits of technology. Motivated by new challenges and driven by growth, I am 
          constantly seeking out new opportunities to learn and expand my skill set.
            </p>

            <p>
            Currently, I'm a Research Intern at{' '}<a href="https://www.bell-labs.com/">Nokia Bell Labs</a> working on Efficient Deep Learning network optimizations like Structural Pruning, Inter-class Similarity and Image Scale guided Neural Network Selection.
            </p>

            <p>
            Previously, I was a Research Assistant at{' '}<a href="http://www.pace.cs.stonybrook.edu/">PACE Lab</a> in Stony Brook University, where we focus on optimizations of Computer Vision and Machine Learning systems. My project was centered on creating a "Decentralized Modular Video Analytics". The goal is to develop a Machine Learning on Edge system with a fast, memory-efficient low-level code to capture high-frequency, high-volume data and squeeze and pipeline compute across a variety of hardware processing units, distributed across multiple system-on-chips.
            </p>

            <p>
            Additionally, I have worked for{' '}<a href="https://www.tifr.res.in/">TIFR</a> to develop a Gujarati Optical Character 
            Recognition model using character level segmentation, transfer-learning (EfficientNet B3) and a Bi-LSTM network to rectify 
            grammatical errors in recognized text.
            </p>

            <p>Here are a few technologies I’ve been working with recently:</p>
          </div>

          <ul className="skills-list">
            {skills && skills.map((skill, i) => <li key={i}>{skill}</li>)}
          </ul>
        </StyledText>

        <StyledPic>
          <div className="wrapper">
            <StaticImage
              className="img"
              src="../../images/me.jpg"
              width={500}
              quality={95}
              formats={['AUTO', 'WEBP', 'AVIF']}
              alt="Headshot"
            />
          </div>
        </StyledPic>
      </div>
    </StyledAboutSection>
  );
};

export default About;
